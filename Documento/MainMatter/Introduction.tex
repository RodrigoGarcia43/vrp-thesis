%===================================================================================
% Chapter: Introduction
%===================================================================================
\chapter*{Introducción}\label{chapter:introduction}
\addcontentsline{toc}{chapter}{Introducción}
%===================================================================================

\qquad 

El problema de enrutamiento de vehículos (VRP por sus siglas en inglés) es uno de los problemas más estudiados en el área de la optimización combinatoria. Fue introducido por primera vez por Dantzig y Ramser en 1959 \cite{Ramsin1959}, quienes propusieron una heurística para enrutar camiones repartidores de gasolina a las estaciones de servicio. Desde ese entonces, gran parte de la comunidad científica y empresarial le ha prestado gran atención, tanto por su complejidad como por sus múltiples aplicaciones \cite{PaoloVigo}.

El VRP, en su versión más general, consiste en diseñar un sistema de rutas que permita satisfacer las demandas de un conjunto de clientes de manera eficiente. El mismo puede estar sujeto a diferentes restricciones que tienen en cuenta elementos como la duración máxima de las rutas, horarios de atención, flotas compuestas por vehículos con diferentes características, servicios de recogida y entrega de mercancía, entre otros aspectos. Las combinaciones entre estas restricciones derivan en distintas variantes del problema original \cite{PaoloVigo}.

El VRP constituye una generalización del problema del viajante (TSP por sus siglas en inglés), por lo tanto pertenece a la clase NP-Duro, al igual que todos sus derivados \cite{PaoloVigo}. De ahí la necesidad de emplear métodos aproximados para su solución. La literatura reporta soluciones a través de métodos exactos para instancias pequeñas \cite{ExactSurveyGilbert, ExactSpanningToth}, mientras que para problemas de mayores dimensiones se han usado heurísticas y metaheurísticas las cuales guían el proceso de búsqueda hacia rutas competitivas de manera eficiente \cite{PaoloVigo} . 

Los problemas complejos del mundo real necesitan algoritmos complejos. En este sentido, los modelos de \textit{machine learning} (aprendizaje automático o ML, por sus siglas en inglés) se sitúan en una de las líneas más populares y de mayor atracción por parte de los investigadores \cite{MLOptimization, MLVRPSurvey}. La optimización es una componente principal en el aprendizaje automático debido a que su esencia es construir un modelo de optimización y aprender los parámetros de la función objetivo a partir de los datos de entrada. Por lo tanto, tienen el potencial de ser aplicables en muchas tareas de optimización, sin la necesidad de construir algoritmos que tomen en consideración múltiples restricciones y enormes espacios de solución.

Como parte de las propuestas de solución a este tipo de problemas combinatorios, se han aplicado satisfactoriamente varias técnicas de aprendizaje automático que van desde \textit{Pointer Networks} \cite{PointerNVinyals, BelloNCORL}, \textit{graph neural networks} \cite{KhaliGraph, AlphaGoMCTS}, \textit{recurrent neural networks} (RNN) \cite{SemiSupAndrew, NazariRL}, \textit{deep reinforcement learning} (DRL) \cite{Nazari2018DeepRL, VeraHVRP, Joe2020DeepRL}, hasta métodos que incorporan heurísticas de búsqueda como \textit{Monte Carlo Tree search} (MCTS) \cite{AlphaGoMCTS, Xing2020AGNMCTS}. En general, estos métodos son capaces de descubrir automáticamente sus propias heurísticas basadas en los datos de entrenamiento.


En la facultad de Matemática y Computación de la Universidad de La Habana, se desarrolla una investigación que tiene como objetivo agilizar el proceso de solución de los problemas VRP para reducir el tiempo y esfuerzo humano dedicado a la búsqueda de soluciones \cite{Camila, Daniela, HectorMasson, JJ}. No obstante a ello, en trabajos anteriores no se había explorado el uso de algoritmos continuos para la solución del VRP. Para ello es necesario convertir el espacio de soluciones discreto del VRP a un espacio de soluciones continuo y esto se puede lograr mediante técnicas de aprendizaje automático, en particular, \textit{autoencoders}.

Las redes neuronales son un conjunto de algoritmos dentro del área de ML cuya esencia es definir una función de transformación $f$ que dada una entrada $x$ se obtenga una salida $y$. Su objetivo es aproximar lo mejor posible $y = f(x, \theta)$ mediante el ajuste de los parámetros $\theta$. Un ejemplo de estas redes son los denominados \textit{autoencoders}. Estos modelos se entrenan para generar una copia de la entrada en la salida, es decir, codifican la entrada a una representación de tamaño fijo, también conocida como código, representación \textit{latente} o vector de contexto, y luego, retornan como salida una reconstrucción de dicha entrada a través de una función decodificadora. El término \textit{latente} quiere decir oculto, pero en estadísticas se usa para referirse a variables que no se observan directamente sino que son inferidas, es decir, no se conoce con certeza la función que la genera \cite{BengioGood}. 

La concepción de los \textit{autoencoders} ha sido parte del panorama histórico de las redes neuronales durante décadas desde 1980 \cite{LeCun1987, HintonAutoencoders}. Tradicionalmente se usan para múltiples propósitos como reducción de dimensión, extracción de características, o pre-entrenamientos no supervisados \cite{Hinton2006, Bengio09, BengioGood}. El mecanismo básico de codificación y decodificación se aplica a una amplia variedad de elementos de entrada.
% bajo la idea de plasmar las características de los valores de entrada en la estructura interna que se refiere como representación latente, código o vector de contexto.
 Su rendimiento está determinado por la capacidad de capturar características propias y representativas de la entrada en el vector de contexto, de forma tal que el espacio formado por dichos vectores constituya un espacio de búsqueda continuo.
 
Con esta tesis se propone transformar el espacio discreto del VRP a un espacio continuo, donde para cada solución del primero, se pueda obtener un vector de $\mathbb{R}^n$ que logre atrapar características y propiedades de interés de la misma. Entiéndase por espacio discreto, a que las soluciones del problema estarán dadas por una lista de rutas y estas, a su vez, por una secuencia de clientes que deben ser visitados en ese orden. Mientras que una solución continua del VRP está constituida por un vector de valores reales que a simple vista no aporta información de la transformación subyacente, pero que a partir de él es posible obtener una solución del espacio discreto usando \textit{autoencoders}.

Esta idea de usar algoritmos continuos para resolver un problema discreto no es nueva. Existen algoritmos genéticos que utilizan vectores numéricos para representar soluciones a problemas de optimización combinatoria como en \textit{Gon{\c{c}}alves et al} \cite{GoncalvesGenAlg}. Sin embargo, estos enfoques se basan en esquemas de decodificación que estan cuidadosamente elaborados por expertos en el dominio. Por el contrario, en la propuesta que se ofrece en este trabajo, el proceso de codificación y decodificación relativo al problema en particular se aprende automáticamente luego de una etapa de entrenamiento del modelo. En este caso, las soluciones del VRP se codifican a un espacio continuo que posteriormente puede ser explorado empleando un algoritmo de optimización continua.

La importancia de este espacio radica en la estructura embebida en cada uno de sus elementos, en el sentido de que soluciones parecidas en el espacio discreto, se ubiquen en regiones cercanas en el continuo, es decir que mantengan una estructura o semántica similar en el espacio correspondiente. Esta peculiaridad entre las codificaciones facilitaría que un algoritmo de búsqueda empleado sobre este espacio se pueda dirigir hacia zonas prometedoras con soluciones de buena calidad para el problema original. 

El estudio y análisis de las propiedades y utilidades de una representación continua para soluciones del VRP resulta de gran interés a lo largo de este trabajo. A esa motivación se suma la introducción hacia nuevas ramas de investigación en el campo de la Inteligencia Artificial, pues los trabajos anteriores pertenecientes a esta línea de investigación en la facultad, no habían tratado técnicas de ML. Como consecuencia surge la siguiente interrogante: ¿Será viable el uso de una arquitectura  \textit{autoencoders} a través de redes neuronales para transformar el espacio discreto de las soluciones del VRP a un espacio continuo? Para lograrlo se propone usar un modelo \textit{autoencoders} capaz de codificar una solución de un problema de enrutamiento a un vector real, y posteriormente decodificarlo nuevamente a una posible solución válida.

 
 

\subsection*{Objetivos}
La investigación tiene como \textbf{objetivo general} la creación de una herramienta que permita transformar el espacio discreto del VRP en un espacio continuo. Para dar cumplimiento a la idea anterior se trazaron los siguientes objetivos específicos:

\subsubsection*{Objetivos específicos}

\begin{enumerate}
	\item Consultar literatura especializada sobre el estado del arte de los problemas VRP, específicamente las propuestas existentes para codificar una solución a un espacio continuo.
	\item Investigar sobre las diferentes arquitecturas del estilo \textit{encoder-decoder} que se aplican en problemas de optimización combinatoria. 
	\item Implementar un modelo que solucione el problema planteado empleando técnicas de aprendizaje automático, en particular, los modelos \textit{autoencoders}.
	\item Crear un marco experimental que permita evaluar distintos modelos \textit{autoencoders} en la tarea de codificación y reconstrucción de soluciones del problema VRP.
	
	\item Analizar los resultados obtenidos a través de un conjunto de métricas y técnicas de visualización del espacio continuo formado.
\end{enumerate}


\subsection*{Organización de la tesis}

El presente documento está organizado en 4 capítulos que recogen las distintas etapas por las que transitó la investigación.


En el capítulo 1 \textbf{Elementos de Aprendizaje Automático} se realiza una introducción a los elementos y conceptos de esta área abordados a lo largo del trabajo.

En el capítulo 2 \textbf{Preliminares}, se presenta un marco teórico con el objetivo de lograr un mejor entendimiento del problema en cuestión y de los métodos escogidos para la solución, sobretodo la teoría de \textit{Autoencoders}. También se reseña el estado actual de la aplicación de estos modelos a problemas de optimización combinatoria, principalmente TSP y VRP; y las técnicas más recientes en los temas tratados. 

El capítulo 3 \textbf{Propuesta de Solución} describe la estructura general de la solución propuesta, desde la etapa de procesamiento y generación de los datos, hasta la especificación y diseño de las componentes que integran la misma. Además se precisan los dos modelos implementados para resolver el problema.

El capítulo 4 \textbf{Experimentos y resultados} comprende los experimentos realizados para validar el modelo, así como las métricas destinadas para su evaluación. 

Por último se ofrecen las conclusiones a partir de los objetivos propuestos y los resultados alcanzados. Adicionalmente se brindan algunas ideas y recomendaciones para trabajos futuros.





