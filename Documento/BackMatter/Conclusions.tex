%===================================================================================
% Chapter: Conclusiones
%===================================================================================
\chapter*{Conclusiones}\label{chapter:conclusions}
\addcontentsline{toc}{chapter}{Conclusiones}
%==================================================================================

%===================================================================================
Con este trabajo se establecen los primeros pasos en la aplicación de algoritmos de aprendizaje automático al problema de enrutamiento de vehículos en la facultad. A partir del estudio realizado sobre los modelos de redes neuronales \textit{autoencoders} se propone una herramienta que permite obtener un espacio de soluciones continuas a partir de soluciones del problema de enrutamiento en un espacio discreto. 

Como parte de la solución se formularon dos modelos: \textit{LinearAEC} y \textit{VAE}, cuya esencia es describir una distribución de probabilidad de los puntos que constituyen la codificación continua de las soluciones de entrada. El comportamiento de ambos modelos fue similar en los experimentos realizados. A pesar de no proporcionar una buena reconstrucción de la solución inicial,  muestra una efectividad del $85\%$ en la generación de soluciones válidas en el proceso de decodificación. Con este resultado, se evidencia la capacidad de ambas propuestas como modelos generativos.

También se plantea y analiza una forma de representar las soluciones del VRP mediante matrices binarias con posibles valores en el conjunto $\{0, 1\}$. En los espacios latentes graficados, se observa un predominio de soluciones con cantidad de rutas cercanas a la cantidad de rutas presente en las soluciones de entrada. 






% Chapter: Recomendaciones
%===================================================================================
\chapter*{Recomendaciones}\label{chapter:recomendaciones}
\addcontentsline{toc}{chapter}{Recomendaciones}
%===================================================================================

Como recomendaciones y trabajos futuros, se propone considerar los siguientes puntos para mejorar los resultados de este trabajo:
\begin{itemize}
	\item Mejorar el marco donde se realizaron los experimentos para probar modelos más complejos y con mayor cantidad y diversidad de casos entrenantes.
	
	\item Utilizar un algoritmo de optimización continua sobre el espacio latente generado con el obetivo de explorarlo y encontrar nuevas soluciones.
	
	\item Añadir técnicas de \textit{reinforcement learning} para mejorar el desempeño del modelo. 
	
	\item Modelar el problema como una arquitectura \textit{sequence-to-sequence} para examinar el uso de redes neuronales recurrentes en estos modelos.
	
	\item Entrenar el modelo con otra representación vectorial de las soluciones del VRP.
	
	%\item Añadir las restricciones y funciones de costo del problema VRP en el aprendizaje puede proveer información valiosa sobre la calidad de las soluciones.
	
	\item Intentar generalizar los modelos para permitir la entrada de soluciones con distinta cantidad de clientes, o sea, que el proceso de aprendizaje no dependa de $n$.
\end{itemize}



% que el modelo no dependa de n
% mejorar el escenario donde se reaizaron los experimetos para probar modelos más complejos y con mayor cant de datos entrenantes
% utiltizar un algoritmo de optimización continua sober el espacio latente generado
% añadir técnicas de RL para mejorar el desempeño del modelo
% modelar el problema como un caso de seq2seqs
% probrar con otra representación de las soluciones iniciales
% añadir las restricciones y funciones de costo en el aprendizaje, puede proveer información valiosa durante el entrenamiento